<?xml version="1.0" encoding="UTF-8"?>
<document language="en">
<meta>
<genre/>
<title>H-38</title>
<authors/>
<date>10-06-2017</date>
<source/>
<complexity_level/>
<uri/>
</meta>
<body>
<p id="0">While the PageRank algorithm [13] has proven to be very effective for ranking Web pages, inaccurate PageRank results are induced because of web page manipulations by people for commercial interests. The manipulation problem is also called the Web spam, which refers to hyperlinked pages on the World Wide Web that are created with the intention of misleading search engines [7]. It is reported that approximately 70% of all pages in the .biz domain and about 35% of the pages in the .us domain belong to the spam category [12]. The reason for the increasing amount of Web spam is explained in [12]: some web site operators try to influence the positioning of their pages within search results because of the large fraction of web traffic originating from searches and the high potential monetary value of this traffic.</p>
<p id="1">From the viewpoint of the Web site operators who want to increase the ranking value of a particular page for search engines, Keyword Stuffing and Link Stuffing are being used widely [7, 12]. From the viewpoint of the search engine managers, the Web spam is very harmful to the users" evaluations and thus their preference to choosing search engines because people believe that a good search engine should not return irrelevant or low-quality results. There are two methods being employed to combat the Web spam problem. Machine learning methods are employed to handle the keyword stuffing. To successfully apply machine learning methods, we need to dig out some useful textual features for Web pages, to mark part of the Web pages as either spam or non-spam, then to apply supervised learning techniques to mark other pages. For example, see [5, 12]. Link analysis methods are also employed to handle the link stuffing problem. One example is the TrustRank [7], a link-based method, in which the link structure is utilized so that human labelled trusted pages can propagate their trust scores trough their links.</p>
<p id="2">This paper focuses on the link-based method.</p>
<p id="3">The rest of the materials are organized as follows. In the next section, we give a brief literature review on various related ranking techniques. We establish the Heat Diffusion Model (HDM) on various cases in Section 3, and propose DiffusionRank in Section 4. In Section 5, we describe the data sets that we worked on and the experimental results.</p>
<p id="4">Finally, we draw conclusions in Section 6.</p>
<p id="5">The importance of a Web page is determined by either the textual content of pages or the hyperlink structure or both. As in previous work [7, 13], we focus on ranking methods solely determined by hyperlink structure of the Web graph. All the mentioned ranking algorithms are established on a graph. For our convenience, we first give some notations. Denote a static graph by G = (V, E), where V = {v1, v2, . . . , vn}, E = {(vi, vj) | there is an edge from vi to vj}. Ii and di denote the in-degree and the out-degree of page i respectively.</p>
<p id="6">The importance of a Web page is an inherently subjective matter, which depends on the reader"s interests, knowledge and attitudes [13]. However, the average importance of all readers can be considered as an objective matter. PageRank tries to find such average importance based on the Web link structure, which is considered to contain a large amount of statistical data. The Web is modelled by a directed graph G in the PageRank algorithms, and the rank or importance xi for page vi ∈ V is defined recursively in terms of pages which point to it: xi = (j,i)∈E aijxj, where aij is assumed to be 1/dj if there is a link from j to i, and 0 otherwise. Or in matrix terms, x = Ax. When the concept of random jump is introduced, the matrix form is changed to x = [(1 − α)g1T + αA]x, (1) where α is the probability of following the actual link from a page, (1 − α) is the probability of taking a random jump, and g is a stochastic vector, i.e., 1T g = 1. Typically, α =</p>
<p id="7">n</p>
<p id="8">the vector of all ones [6, 13].</p>
<p id="9">TrustRank [7] is composed of two parts. The first part is the seed selection algorithm, in which the inverse PageRank was proposed to help an expert of determining a good node. The second part is to utilize the biased PageRank, in which the stochastic distribution g is set to be shared by all the trusted pages found in the first part. Moreover, the initial input of x is also set to be g. The justification for the inverse PageRank and the solid experiments support its advantage in combating the Web spam. Although there are many variations of PageRank, e.g., a family of link-based ranking algorithms in [2], TrustRank is especially chosen for comparisons for three reasonss: (1) it is designed for combatting spamming; (2) its fixed parameters make a comparison easy; and (3) it has a strong theoretical relations with PageRank and DiffusionRank.</p>
<p id="10">In [17], the idea of ranking on the data manifolds was proposed. The data points represented as vectors in Euclidean space are considered to be drawn from a manifold. From the data points on such a manifold, an undirected weighted graph is created, then the weight matrix is given by the Gaussian Kernel smoothing. While the manifold ranking algorithm achieves an impressive result on ranking images, the biased vector g and the parameter k in the general personalized PageRank in [17] are unknown in the Web graph setting; therefore we do not include it in the comparisons.</p>
<p id="11">Heat diffusion is a physical phenomena. In a medium, heat always flow from position with high temperature to position with low temperature. Heat kernel is used to describe the amount of heat that one point receives from another point. Recently, the idea of heat kernel on a manifold is borrowed in applications such as dimension reduction [3] and classification [9, 10, 14]. In these work, the input data is considered to lie in a special structure.</p>
<p id="12">All the above topics are related to our work. The readers can find that our model is a generalization of PageRank in order to resist Web manipulation, that we inherit the first part of TrustRank, that we borrow the concept of ranking on the manifold to introduce our model, and that heat diffusion is a main scheme in this paper.</p>
<p id="13">Heat diffusion provides us with another perspective about how we can view the Web and also a way to calculate ranking values. In this paper, the Web pages are considered to be drawn from an unknown manifold, and the link structure forms a directed graph, which is considered as an approximation to the unknown manifold. The heat kernel established on the Web graph is considered as the representation of the relationship between Web pages. The temperature distribution after a fixed time period, induced by a special initial temperature distribution, is considered as the rank scores on the Web pages. Before establishing the proposed models, we first show our motivations.</p>
<p id="14">There are two points to explain that PageRank is susceptible to web spam. • Over-democratic. There is a belief behind PageRank-all pages are born equal. This can be seen from the equal voting ability of one page: the sum of each column is equal to one. This equal voting ability of all pages gives the chance for a Web site operator to increase a manipulated page by creating a large number of new pages pointing to this page since all the newly created pages can obtain an equal voting right. • Input-independent. For any given non-zero initial input, the iteration will converge to the same stable distribution corresponding to the maximum eigenvalue</p>
<p id="15">property makes it impossible to set a special initial input (larger values for trusted pages and less values even negative values for spam pages) to avoid web spam.</p>
<p id="16">The input-independent feature of PageRank can be further explained as follows. P = [(1 − α)g1T + αA] is a positive stochastic matrix if g is set to be a positive stochastic vector (the uniform distribution is one of such settings), and so the largest eigenvalue is 1 and no other eigenvalue whose absolute value is equal to 1, which is guaranteed by the Perron Theorem [11]. Let y be the eigenvector corresponding to 1, then we have Py = y. Let {xk} be the sequence generated from the iterations xk+1 = Pxk, and x0 is the initial input.</p>
<p id="17">If {xk} converges to x, then xk+1 = Pxk implies that x must satisfy Px = x. Since the only maximum eigenvalue is 1, we have x = cy where c is a constant, and if both x and y are normalized by their sums, then c = 1. The above discussions show that PageRank is independent of the initial input x0.</p>
<p id="18">In our opinion, g and α are objective parameters determined by the users" behaviors and preferences. A, α and g are the true web structure. While A is obtained by a crawler and the setting α = 0.85 is accepted by the people, we think that g should be determined by a user behavior investigation, something like [1]. Without any prior knowledge, g has to be set as g = 1 n</p>
<p id="19">TrustRank model does not follow the true web structure by setting a biased g, but the effects of combatting spamming are achieved in [7]; PageRank is on the contrary in some ways. We expect a ranking algorithm that has an effect of anti-manipulation as TrustRank while respecting the true web structure as PageRank.</p>
<p id="20">We observe that the heat diffusion model is a natural way to avoid the over-democratic and input-independent feature of PageRank. Since heat always flows from a position with higher temperatures to one with lower temperatures, points are not equal as some points are born with high temperatures while others are born with low temperatures. On the other hand, different initial temperature distributions will give rise to different temperature distributions after a fixed time period. Based on these considerations, we propose the novel DiffusionRank. This ranking algorithm is also motivated by the viewpoint for the Web structure. We view all the Web pages as points drawn from a highly complex geometric structure, like a manifold in a high dimensional space. On a manifold, heat can flow from one point to another through the underlying geometric structure in a given time period. Different geometric structures determine different heat diffusion behaviors, and conversely the diffusion behavior can reflect the geometric structure. More specifically, on the manifold, the heat flows from one point to another point, and in a given time period, if one point x receives a large amount of heat from another point y, we can say x and y are well connected, and thus x and y have a high similarity in the sense of a high mutual connection.</p>
<p id="21">We note that on a point with unit mass, the temperature and the heat of this point are equivalent, and these two terms are interchangeable in this paper. In the following, we first show the HDM on a manifold, which is the origin of HDM, but cannot be employed to the World Wide Web directly, and so is considered as the ideal case. To connect the ideal case and the practical case, we then establish HDM on a graph as an intermediate case. To model the real world problem, we further build HDM on a random graph as a practical case. Finally we demonstrate the DiffusionRank which is derived from the HDM on a random graph.</p>
<p id="22">If the underlying manifold is known, the heat flow throughout a geometric manifold with initial conditions can be described by the following second order differential equation: ∂f(x,t) ∂t − ∆f(x, t) = 0, where f(x, t) is the heat at location x at time t, and ∆f is the Laplace-Beltrami operator on a function f. The heat diffusion kernel Kt(x, y) is a special solution to the heat equation with a special initial condition-a unit heat source at position y when there is no heat in other positions. Based on this, the heat kernel Kt(x, y) describes the heat distribution at time t diffusing from the initial unit heat source at position y, and thus describes the connectivity (which is considered as a kind of similarity) between x and y. However, it is very difficult to represent the World Wide Web as a regular geometry with a known dimension; even the underlying is known, it is very difficult to find the heat kernel Kt(x, y), which involves solving the heat equation with the delta function as the initial condition. This motivates us to investigate the heat flow on a graph. The graph is considered as an approximation to the underlying manifold, and so the heat flow on the graph is considered as an approximation to the heat flow on the manifold.</p>
<p id="23">On an undirected graph G, the edge (vi, vj) is considered as a pipe that connects nodes vi and vj. The value fi(t) describes the heat at node vi at time t, beginning from an initial distribution of heat given by fi(0) at time zero. f(t) (f(0)) denotes the vector consisting of fi(t) (fi(0)).</p>
<p id="24">We construct our model as follows. Suppose, at time t, each node i receives M(i, j, t, ∆t) amount of heat from its neighbor j during a period of ∆t. The heat M(i, j, t, ∆t) should be proportional to the time period ∆t and the heat difference fj(t) − fi(t). Moreover, the heat flows from node j to node i through the pipe that connects nodes i and j.</p>
<p id="25">Based on this consideration, we assume that M(i, j, t, ∆t) = γ(fj(t) − fi(t))∆t. As a result, the heat difference at node i between time t + ∆t and time t will be equal to the sum of the heat that it receives from all its neighbors. This is formulated as fi(t + ∆t) − fi(t) = j:(j,i)∈E γ(fj(t) − fi(t))∆t, (2) where E is the set of edges. To find a closed form solution to Eq. (2), we express it in a matrix form: (f(t + ∆t) − f(t))/∆t = γHf(t), where d(v) denotes the degree of the node v. In the limit ∆t → 0, it becomes d dt f(t) = γHf(t).</p>
<p id="26">Solving it, we obtain f(t) = eγtH f(0), especially we have f(1) = eγH f(0), Hij =    −d(vj), j = i, 1, (vj, vi) ∈ E, 0, otherwise, (3) where eγH is defined as eγH = I+γH+ γ2 2! H2 + γ3 3! H3 +· · · .</p>
<p id="27">The above heat diffusion model must be modified to fit the situation where the links between Web pages are directed.</p>
<p id="28">On one Web page, when the page-maker creates a link (a, b) to another page b, he actually forces the energy flow, for example, people"s click-through activities, to that page, and so there is added energy imposed on the link. As a result, heat flows in a one-way manner, only from a to b, not from b to a. Based on such consideration, we modified the heat diffusion model on an undirected graph as follows.</p>
<p id="29">On a directed graph G, the pipe (vi, vj) is forced by added energy such that heat flows only from vi to vj. Suppose, at time t, each node vi receives RH = RH(i, j, t, ∆t) amount of heat from vj during a period of ∆t. We have three assumptions: (1) RH should be proportional to the time period ∆t; (2) RH should be proportional to the the heat at node vj; and (3) RH is zero if there is no link from vj to vi. As a result, vi will receive j:(vj ,vi)∈E σjfj(t)∆t amount of heat from all its neighbors that points to it.</p>
<p id="30">On the other hand, node vi diffuses DH(i, t, ∆t) amount of heat to its subsequent nodes. We assume that: (1) The heat DH(i, t, ∆t) should be proportional to the time period ∆t. (2) The heat DH(i, t, ∆t) should be proportional to the the heat at node vi. (3) Each node has the same ability of diffusing heat. This fits the intuition that a Web surfer only has one choice to find the next page that he wants to browse. (4) The heat DH(i, t, ∆t) should be uniformly distributed to its subsequent nodes. The real situation is more complex than what we assume, but we have to make this simple assumption in order to make our model concise. As a result, node vi will diffuse γfi(t)∆t/di amount of heat to any of its subsequent nodes, and each of its subsequent node should receive γfi(t)∆t/di amount of heat. Therefore σj = γ/dj.</p>
<p id="31">To sum up, the heat difference at node vi between time t+∆t and time t will be equal to the sum of the heat that it receives, deducted by what it diffuses. This is formulated as fi(t + ∆t) − fi(t) = −γfi(t)∆t + j:(vj ,vi)∈E γ/djfj(t)∆t.</p>
<p id="32">Similarly, we obtain f(1) = eγH f(0), Hij =    −1, j = i, 1/dj, (vj, vi) ∈ E, 0, otherwise. (4)</p>
<p id="33">For real world applications, we have to consider random edges. This can be seen in two viewpoints. The first one is that in Eq. (1), the Web graph is actually modelled as a random graph, there is an edge from node vi to node vj with a probability of (1 − α)gj (see the item (1 − α)g1T ), and that the Web graph is predicted by a random graph [15, 16]. The second one is that the Web structure is a random graph in essence if we consider the content similarity between two pages, though this is not done in this paper.</p>
<p id="34">For these reasons, the model would become more flexible if we extend it to random graphs. The definition of a random graph is given below.</p>
<p id="35">Definition 1. A random graph RG = (V, P = (pij)) is defined as a graph with a vertex set V in which the edges are chosen independently, and for 1 ≤ i, j ≤ |V | the probability of (vi, vj) being an edge is exactly pij.</p>
<p id="36">The original definition of random graphs in [4], is changed slightly to consider the situation of directed graphs. Note that every static graph can be considered as a special random graph in the sense that pij can only be 0 or 1.</p>
<p id="37">On a random graph RG = (V, P), where P = (pij) is the probability of the edge (vi, vj) exists. In such a random graph, the expected heat difference at node i between time t + ∆t and time t will be equal to the sum of the expected heat that it receives from all its antecedents, deducted by the expected heat that it diffuses.</p>
<p id="38">Since the probability of the link (vj, vi) is pji, the expected heat flow from node j to node i should be multiplied by pji, and so we have fi(t + ∆t) − fi(t) = −γ fi(t) ∆t + j:(vj ,vi)∈E γpjifj(t)∆t/RD+ (vj), where RD+ (vi) is the expected out-degree of node vi, it is defined as k pik.</p>
<p id="39">Similarly we have f(1) = eγR f(0), Rij =    −1, j = i; pji/RD+ (vj), j = i. (5) When the graph is large, a direct computation of eγR is time-consuming, and we adopt its discrete approximation: f(1) = (I + γ N R)N f(0). (6) The matrix (I+ γ N R)N in Eq. (6) and matrix eγR in Eq. (5) are called Discrete Diffusion Kernel and the Continuous Diffusion Kernel respectively. Based on the Heat Diffusion Models and their solutions, DiffusionRank can be established on undirected graphs, directed graphs, and random graphs. In the next section, we mainly focus on DiffusionRank in the random graph setting.</p>
<p id="40">For a random graph, the matrix (I + γ N R)N or eγR can measure the similarity relationship between nodes. Let fi(0)= 1, fj(0) = 0 if j = i, then the vector f(0) represent the unit heat at node vi while all other nodes has zero heat. For such f(0) in a random graph, we can find the heat distribution at time 1 by using Eq. (5) or Eq. (6). The heat distribution is exactly the i−th row of the matrix of (I + γ N R)N or eγR . So the ith-row jth-column element hij in the matrix (I + γ∆tR)N or eγR means the amount of heat that vi can receive from vj from time 0 to 1. Thus the value hij can be used to measure the similarity from vj to vi. For a static graph, similarly the matrix (I + γ N H)N or eγH can measure the similarity relationship between nodes.</p>
<p id="41">The intuition behind is that the amount h(i, j) of heat that a page vi receives from a unit heat in a page vj in a unit time embodies the extent of the link connections from page vj to page vi. Roughly speaking, when there are more uncrossed paths from vj to vi, vi will receive more heat from vj; when the path length from vj to vi is shorter, vi will receive more heat from vj; and when the pipe connecting vj and vi is wide, the heat will flow quickly. The final heat that vi receives will depend on various paths from vj to vi, their length, and the width of the pipes.</p>
<p id="42">Algorithm 1 DiffusionRank Function Input: The transition matrix A; the inverse transition matrix U; the decay factor αI for the inverse PageRank; the decay factor αB for PageRank; number of iterations MI for the inverse PageRank; the number of trusted pages L; the thermal conductivity coefficient γ.</p>
<p id="43">Output: DiffusionRank score vector h. 1: s = 1 2: for i = 1 TO MI do 3: s = αI · U · s + (1 − αI ) · 1 n · 1 4: end for 5: Sort s in a decreasing order: π = Rank({1, . . . , n}, s) 6: d = 0, Count = 0, i = 0 7: while Count ≤ L do 8: if π(i) is evaluated as a trusted page then 9: d(π(i)) = 1, Count + + 10: end if 11: i + + 12: end while 13: d = d/|d| 14: h = d 15: Find the iteration number MB according to λ 16: for i = 1 TO MB do 17: h = (1 − γ MB )h + γ MB (αB · A · h + (1 − αB) · 1 n · 1) 18: end for 19: RETURN h</p>
<p id="44">For the ranking task, we adopt the heat kernel on a random graph. Formally the DiffusionRank is described in Algorithm 1, in which,the element Uij in the inverse transition matrix U is defined to be 1/Ij if there is a link from i to j, and 0 otherwise. This trusted pages selection procedure by inverse PageRank is completely borrowed from TrustRank [7] except for a fix number of the size of the trusted set.</p>
<p id="45">Although the inverse PageRank is not perfect in its ability of determining the maximum coverage, it is appealing because of its polynomial execution time and its reasonable intuition-we actually inverse the original link when we try to build the seed set from those pages that point to many pages that in turn point to many pages and so on. In the algorithm, the underlying random graph is set as P = αB · A + (1 − αB) · 1 n · 1n×n, which is induced by the Web graph. As a result, R = −I + P.</p>
<p id="46">In fact, the more general setting for DiffusionRank is P = αB ·A+(1−αB)· 1 n ·g·1T . By such a setting, DiffusionRank is a generalization of TrustRank when γ tends to infinity and when g is set in the same way as TrustRank. However, the second part of TrustRank is not adopted by us. In our model, g should be the true teleportation determined by the user"s browse habits, popularity distribution over all the Web pages, and so on; P should be the true model of the random nature of the World Wide Web. Setting g according to the trusted pages will not be consistent with the basic idea of Heat Diffusion on a random graph. We simply set g = 1 only because we cannot find it without any priori knowledge.</p>
<p id="47">Remark. In a social network interpretation,</p>
<p id="48">DiffusionRank first recognizes a group of trusted people, who may not be highly ranked, but they know many other people.</p>
<p id="49">The initially trusted people are endowed with the power to decide who can be further trusted, but cannot decide the final voting results, and so they are not dictators.</p>
<p id="50">Next we show the four advantages for DiffusionRank.</p>
<p id="51">First, its solutions have two forms, both of which are closed form. One takes the discrete form, and has the advantage of fast computing while the other takes the continuous form, and has the advantage of being easily analyzed in theoretical aspects. The theoretical advantage has been shown in the proof of theorem in the next section. (a) Group to Group Relations (b) An undirected graph Figure 1: Two graphs</p>
<p id="52">Second, it can be naturally employed to detect the groupgroup relation. For example, let G2 and G1 denote two groups, containing pages (j1, j2, . . . , js) and (i1, i2, . . . , it), respectively. Then u,v hiu,jv is the total amounts of heat that G1 receives from G2, where hiu,jv is the iu−th row jv−th column element of the heat kernel. More specifically, we need to first set f(0) for such an application as follows.</p>
<p id="53">In f(0) = (f1(0), f2(0), . . . , fn(0))T , if i ∈ {j1, j2, . . . , js}, then fi(0) = 1, and 0 otherwise. Then we employ Eq. (5) to calculate f(1) = (f1(1), f2(1), . . . , fn(1))T , finally we sum those fj(1) where j ∈ {i1, i2, . . . , it}. Fig. 1 (a) shows the results generated by the DiffusionRank. We consider five groups-five departments in our Engineering Faculty: CSE,</p>
<p id="54">MAE, EE, IE, and SE. γ is set to be 1, the numbers in Fig. 1 (a) are the amount of heat that they diffuse to each other. These results are normalized by the total number of each group, and the edges are ignored if the values are less than 0.000001. The group-to-group relations are therefore detected, for example, we can see that the most strong overall tie is from EE to IE. While it is a natural application for DiffusionRank because of the easy interpretation by the amount heat from one group to another group, it is difficult to apply other ranking techniques to such an application because they lack such a physical meaning.</p>
<p id="55">Third, it can be used to partition the Web graph into several parts. A quick example is shown below. The graph in Fig. 1 (b) is an undirected graph, and so we employ the Eq. (3). If we know that node 1 belongs to one community and that node 12 belongs to another community, then we can put one unit positive heat source on node 1 and one unit negative heat source on node 12. After time 1, if we set γ = 0.5, the heat distribution is [0.25, 0.16, 0.17,</p>
<p id="56">we set γ = 1, it will be [0.17, 0.16, 0.17, 0.16, 0.16, 0.12,</p>
<p id="57">can easily divide the graph into two parts: {1, 2, 3, 4, 5, 6, 7} with positive temperatures and {8, 9, 10, 11, 12} with negative temperatures. For directed graphs and random graphs, similarly we can cut them by employing corresponding heat solution.</p>
<p id="58">Fourth, it can be used to combat manipulation. Let G2 contain trusted Web pages (j1, j2, . . . , js), then for each page i, v hi,jv is the heat that page i receives from G2, and can be computed by the discrete approximation of Eq. (4) in the case of a static graph or Eq. (6) in the case of a random graph, in which f(0) is set to be a special initial heat distribution so that the trusted Web pages have unit heat while all the others have zero heat. In doing so, manipulated Web page will get a lower rank unless it has strong in-links from the trusted Web pages directly or indirectly. The situation is quite different for PageRank because PageRank is inputindependent as we have shown in Section 3.1. Based on the fact that the connection from a trusted page to a bad page should be weak-less uncross paths, longer distance and narrower pipe, we can say DiffusionRank can resist web spam if we can select trusted pages. It is fortunate that the trusted pages selection method in [7]-the first part of TrustRank can help us to fulfill this task. For such an application of DiffusionRank, the computation complexity for Discrete Diffusion Kernel is the same as that for PageRank in cases of both a static graph and a random graph. This can be seen in Eq. (6), by which we need N iterations and for each iteration we need a multiplication operation between a matrix and a vector, while in Eq. (1) we also need a multiplication operation between a matrix and a vector for each iteration.</p>
<p id="59">γ plays an important role in the anti-manipulation effect of DiffusionRank. γ is the thermal conductivity-the heat diffusion coefficient. If it has a high value, heat will diffuse very quickly. Conversely, if it is small, heat will diffuse slowly. In the extreme case, if it is infinitely large, then heat will diffuse from one node to other nodes immediately, and this is exactly the case corresponding to PageRank. Next, we will interpret it mathematically.</p>
<p id="60">Theorem 1. When γ tends to infinity and f(0) is not the zero vector, eγR f(0) is proportional to the stable distribution produced by PageRank.</p>
<p id="61">Let g = 1 n</p>
<p id="62">that 1 is the largest eigenvalue of P = [(1 − α)g1T + αA], and that no other eigenvalue whose absolute value is equal to 1. Let x be the stable distribution, and so Px = x. x is the eigenvector corresponding to the eigenvalue 1. Assume the n − 1 other eigenvalues of P are |λ2| &lt; 1, . . . , |λn| &lt; 1, we can find an invertible matrix S = ( x S1 ) such that S−1 PS =     </p>
<p id="63">... ∗</p>
<p id="64">     . (7) Since eγR = eγ(−I+P) = S−1     </p>
<p id="65">∗ ∗</p>
<p id="66">... ∗</p>
<p id="67">     S, (8) all eigenvalues of the matrix eγR are 1, eγ(λ2−1) , . . . , eγ(λn−1) .</p>
<p id="68">When γ → ∞, they become 1, 0, . . . , 0, which means that 1 is the only nonzero eigenvalue of eγR when γ → ∞. We can see that when γ → ∞, eγR eγR f(0) = eγR f(0), and so eγR f(0) is an eigenvector of eγR when γ → ∞. On the other hand, eγR x = (I+γR+γ2 2! R2 +γ3 3! R3 +. . .)x = Ix+γRx+γ2 2! R2 x+ γ3 3! R3 x + . . . = x since Rx = (−I + P)x = −x + x = 0, and hence x is the eigenvector of eγR for any γ. Therefore both x and eγR f(0) are the eigenvectors corresponding the unique eigenvalue 1 of eγR when γ → ∞, and consequently x = ceγR f(0).</p>
<p id="69">By this theorem, we see that DiffusionRank is a generalization of PageRank. When γ = 0, the ranking value is most robust to manipulation since no heat is diffused and the system is unchangeable, but the Web structure is completely ignored since eγR f(0) = e0R f(0) = If(0) = f(0); when γ = ∞, DiffusionRank becomes PageRank, it can be manipulated easily. We expect an appropriate setting of γ that can balance both. For this, we have no theoretical result, but in practice we find that γ = 1 works well in Section 5. Next we discuss how to determine the number of iterations if we employ the discrete heat kernel.</p>
<p id="70">While we enjoy the advantage of the concise form of the exponential heat kernel, it is better for us to calculate DiffusionRank by employing Eq. (6) in an iterative way. Then the problem about determining N-the number of iterations arises: For a given threshold , find N such that ||((I + γ N R)N − eγR )f(0)|| &lt; for any f(0) whose sum is one.</p>
<p id="71">Since it is difficult to solve this problem, we propose a heuristic motivated by the following observations. When R = −I+P, by Eq. (7), we have (I+ γ N R)N = (I+ γ N (−I+ P))N = S−1     </p>
<p id="72">N )N ∗ ∗</p>
<p id="73">... ∗</p>
<p id="74">N )N      S. (9) Comparing Eq. (8) and Eq. (9), we observe that the eigenvalues of (I + γ N R)N − eγR are (1 + γ(λn−1) N )N − eγ(λn−1) .</p>
<p id="75">We propose a heuristic method to determine N so that the difference between the eigenvalues are less than a threshold for only positive λs.</p>
<p id="76">We also observe that if γ = 1, λ &lt; 1, then |(1+ γ(λ−1) N )N − eγ(λ−1) | &lt; 0.005 if N ≥ 100, and |(1+ γ(λ−1) N )N −eγ(λ−1) | &lt;</p>
<p id="77">according to different accuracy requirements. In this paper, we use the relatively accurate setting N = 100 to make the real eigenvalues in (I + γ N R)N − eγR less than 0.005.</p>
<p id="78">In this section, we show the experimental data, the methodology, the setting, and the results.</p>
<p id="79">Our input data consist of a toy graph, a middle-size realworld graph, and a large-size real-world graph. The toy graph is shown in Fig. 2 (a). The graph below it shows node</p>
<p id="80">such that they all point to node 1, and node 1 points to them all. The data of two real Web graph were obtained from the domain in our institute in October, 2004. The total number of pages found are 18,542 in the middle-size graph, and 607,170 in the large-size graph respectively. The middle-size graph is a subgraph of the large-size graph, and they were obtained by the same crawler: one is recorded by the crawler in its earlier time, and the other is obtained when the crawler stopped.</p>
<p id="81">The algorithms we run include PageRank, TrustRank and DiffusionRank. All the rank values are multiplied by the number of nodes so that the sum of the rank values is equal to the number of nodes. By this normalization, we can compare the results on graphs with different sizes since the average rank value is one for any graph after such normalization.</p>
<p id="82">We will need value difference and pairwise order difference as comparison measures. Their definitions are listed as follows.</p>
<p id="83">Value Difference. The value difference between A = {Ai}n i=1 and B = {Bi}n i=1 is measured as n i=1 |Ai − Bi|.</p>
<p id="84">Pairwise Order Difference. The order difference between A and B is measured as the number of significant order differences between A and B. The pair (A[i], A[j]) and (B[i], B[j]) is considered as a significant order difference if one of the following cases happens: both A[i] &gt; [ &lt;]A[j]+0.1 and B[i] ≤ [ ≥]A[j]; both A[i] ≤ [ ≥]A[j] and B[i] &gt; [ &lt; ]A[j] + 0.1.</p>
<p id="85">A 1 B C ... 2 5</p>
<p id="86">4 1</p>
<p id="87">0 2 4 6 8 10 12 Gamma ValueDifference Trust set={1} Trust set={2} Trust set={3} Trust set={4} Trust set={5} Trust set={6} (a) (b) Figure 2: (a) The toy graph consisting of six nodes, and node 1 is being manipulated by adding new nodes A, B, C, . . . (b) The approximation tendency to PageRank by DiffusionRank</p>
<p id="88">The experiments on the middle-size graph and the largesize graphs are conducted on the workstation, whose hardware model is Nix Dual Intel Xeon 2.2GHz with 1GB RAM and a Linux Kernel 2.4.18-27smp (RedHat7.3). In calculating DiffusionRank, we employ Eq. (6) and the discrete approximation of Eq. (4) for such graphs. The related tasks are implemented using C language. While in the toy graph, we employ the continuous diffusion kernel in Eq. (4) and Eq. (5), and implement related tasks using Matlab.</p>
<p id="89">For nodes that have zero out-degree (dangling nodes), we employ the method in the modified PageRank algorithm [8], in which dangling nodes of are considered to have random links uniformly to each node. We set α = αI = αB = 0.85 in all algorithms. We also set g to be the uniform distribution in both PageRank and DiffusionRank. For DiffusionRank, we set γ = 1. According to the discussions in Section 4.3 and Section 4.4, we set the iteration number to be MB = 100 in DiffusionRank, and for accuracy consideration, the iteration number in all the algorithms is set to be 100.</p>
<p id="90">We show that when γ tends to infinity, the value differences between DiffusionRank and PageRank tend to zero.</p>
<p id="91">Fig. 2 (b) shows the approximation property of DiffusionRank, as proved in Theorem 1, on the toy graph. The horizontal axis of Fig. 2 (b) marks the γ value, and vertical axis corresponds to the value difference between DiffusionRank and PageRank. All the possible trusted sets with L = 1 are considered. For L &gt; 1, the results should be the linear combination of some of these curves because of the linearity of the solutions to heat equations. On other graphs, the situations are similar.</p>
<p id="92">In this section, we show how the rank values change as the intensity of manipulation increases. We measure the intensity of manipulation by the number of newly added points that point to the manipulated point. The horizontal axes of Fig. 3 stand for the numbers of newly added points, and vertical axes show the corresponding rank values of the manipulated nodes. To be clear, we consider all six situations.</p>
<p id="93">Every node in Fig. 2 (a) is manipulated respectively, and its</p>
<p id="94">0 10 20 30 40 50 RankoftheManipulatdNode−1 DiffusionRank−Trust 4 PageRank TrustRanl−Trust 4</p>
<p id="95">0 10 20 30 40 50 RankoftheManipulatdNode−2 DiffusionRank−Trust 4 PageRank TrustRanl−Trust 4</p>
<p id="96">0 10 20 30 40 50 RankoftheManipulatdNode−3 DiffusionRank−Trust 4 PageRank TrustRanl−Trust 4</p>
<p id="97">0 10 20 30 40 50 Number of New Added Nodes RankoftheManipulatdNode−4 DiffusionRank−Trust 3 PageRank TrustRanl−Trust 3</p>
<p id="98">0 10 20 30 40 50 Number of New Added Nodes RankoftheManipulatdNode−5 DiffusionRank−Trust 4 PageRank TrustRanl−Trust 4</p>
<p id="99">0 10 20 30 40 50 Number of New Added Nodes RankoftheManipulatdNode−6 DiffusionRank−Trust 4 PageRank TrustRanl−Trust 4 Figure 3: The rank values of the manipulated nodes on the toy graph 200040006000800010000 0 1000 2000 3000 4000 5000 6000 7000 8000 Number of New Added Points RankoftheManipulatdNode PageRank DiffusionRank−uniform DiffusionRank0 DiffusionRank1 DiffusionRank2 DiffusionRank3 TrustRank0 TrustRank1 TrustRank2 TrustRank3</p>
<p id="100">0 20 40 60 80 100 120 140 160 180 Number of New Added Points RankoftheManipulatdNode PageRank DiffusionRank TrustRank DiffusionRank−uniform (a) (b) Figure 4: (a) The rank values of the manipulated nodes on the middle-size graph; (b) The rank values of the manipulated nodes on the large-size graph corresponding values for PageRank, TrustRank (TR),</p>
<p id="101">DiffusionRank (DR) are shown in the one of six sub-figures in Fig. 3. The vertical axes show which node is being manipulated. In each sub-figure, the trusted sets are computed below. Since the inverse PageRank yields the results [1.26, 0.85, 1.31, 1.36, 0.51, 0.71]. Let L = 1. If the manipulated node is not 4, then the trusted set is {4}, and otherwise {3}. We observe that in all the cases, rank values of the manipulated node for DiffusionRank grow slowest as the number of the newly added nodes increases. On the middle-size graph and the large-size graph, this conclusion is also true, see Fig. 4. Note that, in Fig. 4 (a), we choose four trusted sets (L = 1), on which we test DiffusionRank and TrustRank, the results are denoted by DiffusionRanki and TrustRanki (i = 0, 1, 2, 3 denotes the four trusted set); in Fig. 4 (b), we choose one trusted set (L = 1). Moreover, in both Fig. 4 (a) and Fig. 4 (b), we show the results for DiffusionRank when we have no trusted set, and we trust all the pages before some of them are manipulated.</p>
<p id="102">We also test the order difference between the ranking order A before the page is manipulated and the ranking order PA after the page is manipulated. Because after manipulation, the number of pages changes, we only compare the common part of A and PA. This experiment is used to test the stability of all these algorithms. The less the order difference, the stabler the algorithm, in the sense that only a smaller part of the order relations is affected by the manipulation. Figure 5 (a) shows that the order difference values change when we add new nodes that point to the manipulated node. We give several γ settings. We find that when γ = 1, the least order difference is achieved by DiffusionRank. It is interesting to point out that as γ increases, the order difference will increase first; after reaching a maximum value, it will decrease, and finally it tends to the PageRank results. We show this tendency in Fig. 5 (b), in which we choose three different settings-the number of manipulated nodes are 2,000, 5,000, and 10,000 respectively. From these figures, we can see that when γ &lt; 2, the values are less than those for PageRank, and that when γ &gt; 20, the difference between PageRank and DiffusionRank is very small.</p>
<p id="103">After these investigations, we find that in all the graphs we tested, DiffusionRank (when γ = 1) is most robust to manipulation both in value difference and order difference. The trust set selection algorithm proposed in [7] is effective for both TrustRank and DiffusionRank.</p>
<p id="104">0</p>
<p id="105">1</p>
<p id="106">2</p>
<p id="107">3 x 10 5 Number of New Added Points PairwiseOrderDifference PageRank DiffusionRank−Gamma=1 DiffusionRank−Gamma=2 DiffusionRank−Gamma=3 DiffusionRank−Gamma=4 DiffusionRank−Gamma=5 DiffusionRank−Gamma=15 TrustRank</p>
<p id="108">0</p>
<p id="109">1</p>
<p id="110">2</p>
<p id="111">x 10 5 Gamma PairwiseOrderDifference DiffusionRank: when added 2000 nodes DiffusionRank: when added 5000 nodes DiffusionRank: when added 10000 nodes PageRank (a) (b) Figure 5: (a) Pairwise order difference on the middle-size graph, the least it is, the more stable the algorithm; (b) The tendency of varying γ</p>
<p id="112">We conclude that DiffusionRank is a generalization of PageRank, which is interesting in that the heat diffusion coefficient γ can balance the extent that we want to model the original Web graph and the extent that we want to reduce the effect of link manipulations. The experimental results show that we can actually achieve such a balance by setting γ = 1, although the best setting including varying γi is still under further investigation. This anti-manipulation feature enables DiffusionRank to be a candidate as a penicillin for Web spamming. Moreover, DiffusionRank can be employed to find group-group relations and to partition Web graph into small communities. All these advantages can be achieved in the same computational complexity as PageRank. For the special application of anti-manipulation,</p>
<p id="113">DiffusionRank performs best both in reduction effects and in its stability among all the three algorithms.</p>
<p id="114">We thank Patrick Lau, Zhenjiang Lin and Zenglin Xu for their help. This work is fully supported by two grants from the Research Grants Council of the Hong Kong Special administrative Region, China (Project No. CUHK4205/04E and Project No. CUHK4235/04E).</p>
<p id="115">[1] E. Agichtein, E. Brill, and S. T. Dumais. Improving web search ranking by incorporating user behavior information. In E. N.</p>
<p id="116">Efthimiadis, S. T. Dumais, D. Hawking, and K. J¨arvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 19-26, 2006. [2] R. A. Baeza-Yates, P. Boldi, and C. Castillo. Generalizing pagerank: damping functions for link-based ranking algorithms. In E. N. Efthimiadis, S. T. Dumais, D. Hawking, and K. J¨arvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 308-315, 2006. [3] M. Belkin and P. Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. Neural Computation, 15(6):1373-1396, Jun 2003. [4] B. Bollob´as. Random Graphs. Academic Press Inc. (London),</p>
<p id="117">[5] C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds,</p>
<p id="118">N. Hamilton, and G. Hullender. Learning to rank using gradient descent. In Proceedings of the 22nd international conference on Machine learning (ICML), pages 89-96, 2005. [6] N. Eiron, K. S. McCurley, and J. A. Tomlin. Ranking the web frontier. In Proceeding of the 13th World Wide Web Conference (WWW), pages 309-318, 2004. [7] Z. Gy¨ongyi, H. Garcia-Molina, and J. Pedersen. Combating web spam with trustrank. In M. A. Nascimento, M. T. ¨Ozsu,</p>
<p id="119">D. Kossmann, R. J. Miller, J. A. Blakeley, and K. B. Schiefer, editors, Proceedings of the Thirtieth International Conference on Very Large Data Bases (VLDB), pages 576-587, 2004. [8] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H.</p>
<p id="120">Golub. Exploiting the block structure of the web for computing pagerank. Technical report, Stanford University, 2003. [9] R. I. Kondor and J. D. Lafferty. Diffusion kernels on graphs and other discrete input spaces. In C. Sammut and A. G.</p>
<p id="121">Hoffmann, editors, Proceedings of the Nineteenth International Conference on Machine Learning (ICML), pages 315-322, 2002. [10] J. Lafferty and G. Lebanon. Diffusion kernels on statistical manifolds. Journal of Machine Learning Research, 6:129-163,</p>
</body>
</document>
